{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XMyHqa5_ZEVBbEnzBeHfyoZHV9MPsrbC","timestamp":1664556449876}],"collapsed_sections":[],"mount_file_id":"1TSwMlglJSqgjeUrRohvIQLvyUee51PnW","authorship_tag":"ABX9TyMqzfnO5/bn0BBoEU7NE9J2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"943ecd2dd93d49a8999b1cc346f0f113":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64eb40ad213d4d0da9cdf272df840b00","IPY_MODEL_dd004af1472b435b94b97a1978b7ff36","IPY_MODEL_d09ad4aee2294d0fbeb94d6689c35b48"],"layout":"IPY_MODEL_2e311aaff6d8432e9d4b08fe1705e341"}},"64eb40ad213d4d0da9cdf272df840b00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_310d9fe190d24513b4950bf23bc54d40","placeholder":"​","style":"IPY_MODEL_d20ebc172339473abe5756fd516fc052","value":"100%"}},"dd004af1472b435b94b97a1978b7ff36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8c76d02096d40f7830a4edfce1b40fe","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b69df3f9f9794c1ca8fa529b85dbcaae","value":111898327}},"d09ad4aee2294d0fbeb94d6689c35b48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83d60ef4d6cb4a7cb9dbd2c200c44893","placeholder":"​","style":"IPY_MODEL_c3e975a9e9c945cb9b8aee70a968b240","value":" 107M/107M [00:01&lt;00:00, 54.5MB/s]"}},"2e311aaff6d8432e9d4b08fe1705e341":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"310d9fe190d24513b4950bf23bc54d40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20ebc172339473abe5756fd516fc052":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8c76d02096d40f7830a4edfce1b40fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b69df3f9f9794c1ca8fa529b85dbcaae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83d60ef4d6cb4a7cb9dbd2c200c44893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e975a9e9c945cb9b8aee70a968b240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"],"metadata":{"id":"UDeR7xe-jWZ6","executionInfo":{"status":"ok","timestamp":1664796278704,"user_tz":-330,"elapsed":682,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"metadata":{"id":"fjvffi5-jZO0","executionInfo":{"status":"ok","timestamp":1664796279712,"user_tz":-330,"elapsed":10,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"joxB6BB1iMZ4","executionInfo":{"status":"ok","timestamp":1664796279714,"user_tz":-330,"elapsed":11,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"outputs":[],"source":["def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","source":["!pip install facenet_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOnf4yqrxX4H","executionInfo":{"status":"ok","timestamp":1664796284794,"user_tz":-330,"elapsed":4396,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}},"outputId":"a3ab872d-c7be-4f75-be58-4eae0d0cbc2b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet_pytorch\n","  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.21.6)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.13.1+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (4.1.1)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.12.1+cu113)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.2\n"]}]},{"cell_type":"code","source":["# importing libraries\n","\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","import torch\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from PIL import Image\n","import cv2\n","import time\n","import os"],"metadata":{"id":"AwVyI2Gwj_2I","executionInfo":{"status":"ok","timestamp":1664796288968,"user_tz":-330,"elapsed":4180,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# initializing MTCNN and InceptionResnetV1 \n","\n","mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all=False\n","mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) # keep_all=True\n","\n","\n","## Highlight\n","resnet = InceptionResnetV1(pretrained='vggface2').eval()    "],"metadata":{"id":"UxvzBHlXkAQX","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["943ecd2dd93d49a8999b1cc346f0f113","64eb40ad213d4d0da9cdf272df840b00","dd004af1472b435b94b97a1978b7ff36","d09ad4aee2294d0fbeb94d6689c35b48","2e311aaff6d8432e9d4b08fe1705e341","310d9fe190d24513b4950bf23bc54d40","d20ebc172339473abe5756fd516fc052","f8c76d02096d40f7830a4edfce1b40fe","b69df3f9f9794c1ca8fa529b85dbcaae","83d60ef4d6cb4a7cb9dbd2c200c44893","c3e975a9e9c945cb9b8aee70a968b240"]},"executionInfo":{"status":"ok","timestamp":1664796291278,"user_tz":-330,"elapsed":2321,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}},"outputId":"6cecceeb-2812-4ddb-8549-99708e2d1e49"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/107M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"943ecd2dd93d49a8999b1cc346f0f113"}},"metadata":{}}]},{"cell_type":"code","source":["resnet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ne1jOOKcKHk","executionInfo":{"status":"ok","timestamp":1664796291278,"user_tz":-330,"elapsed":8,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}},"outputId":"e455f49b-c938-4784-da5b-de42ce4ff277"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InceptionResnetV1(\n","  (conv2d_1a): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_2a): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_2b): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2d_3b): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_4a): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (conv2d_4b): BasicConv2d(\n","    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (repeat_1): Sequential(\n","    (0): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block35(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (branch2): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (mixed_6a): Mixed_6a(\n","    (branch0): BasicConv2d(\n","      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (repeat_2): Sequential(\n","    (0): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (5): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (6): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (7): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (8): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (9): Block17(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (mixed_7a): Mixed_7a(\n","    (branch0): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (repeat_3): Sequential(\n","    (0): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (1): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (2): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (3): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","    (4): Block8(\n","      (branch0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (branch1): Sequential(\n","        (0): BasicConv2d(\n","          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (1): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","        (2): BasicConv2d(\n","          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU()\n","        )\n","      )\n","      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","      (relu): ReLU()\n","    )\n","  )\n","  (block8): Block8(\n","    (branch0): BasicConv2d(\n","      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (branch1): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (2): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n","  (dropout): Dropout(p=0.6, inplace=False)\n","  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n","  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from torchvision.models import resnet50, ResNet50_Weights\n","import torch.nn as nn\n","resnet5 = resnet50()\n","# resnet5 = resnet5.load_state_dict()\n","\n","new_resnet = nn.Sequential(*list(resnet5.children())[:-1])"],"metadata":{"id":"-3j5VTKqcR2i","executionInfo":{"status":"ok","timestamp":1664796376637,"user_tz":-330,"elapsed":613,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","# Read data from folder\n","\n","dataset = datasets.ImageFolder('/content/drive/MyDrive/photos') # photos folder path \n","idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n","\n","def collate_fn(x):\n","    return x[0]\n","\n","loader = DataLoader(dataset, collate_fn=collate_fn)\n","\n","name_list = [] # list of names corrospoing to cropped photos\n","embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n","\n","for img, idx in loader:\n","    face, prob = mtcnn0(img, return_prob=True) \n","    if face is not None and prob>0.92:\n","        emb = new_resnet(face.unsqueeze(0)).reshape(1, -1)\n","        embedding_list.append(emb.detach()) \n","        name_list.append(idx_to_class[idx])        \n","\n","# save data\n","data = [embedding_list, name_list] \n","torch.save(data, 'new_resnet_data.pt') # saving data.pt file"],"metadata":{"id":"uek3VqaGmtfv","executionInfo":{"status":"ok","timestamp":1664796715296,"user_tz":-330,"elapsed":6536,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"830ea386-d963-4080-9b36-a7cc458b7ca4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 240, 240])\n","1.0\n","torch.Size([3, 240, 240])\n","0.99999845\n","torch.Size([3, 240, 240])\n","0.99997604\n","torch.Size([3, 240, 240])\n","1.0\n","torch.Size([3, 240, 240])\n","0.99982846\n","torch.Size([3, 240, 240])\n","0.99949276\n","torch.Size([3, 240, 240])\n","0.71834964\n","torch.Size([3, 240, 240])\n","0.9991308\n","torch.Size([3, 240, 240])\n","0.9999969\n","torch.Size([3, 240, 240])\n","0.99999666\n","torch.Size([3, 240, 240])\n","0.9999962\n","torch.Size([3, 240, 240])\n","0.9945463\n","torch.Size([3, 240, 240])\n","0.99999535\n","torch.Size([3, 240, 240])\n","0.99992454\n","torch.Size([3, 240, 240])\n","0.99999976\n","torch.Size([3, 240, 240])\n","0.9999565\n"]}]},{"cell_type":"code","source":["# Read data from folder\n","\n","dataset = datasets.ImageFolder('/content/drive/MyDrive/photos') # photos folder path \n","idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n","\n","def collate_fn(x):\n","    return x[0]\n","\n","loader = DataLoader(dataset, collate_fn=collate_fn)\n","\n","name_list = [] # list of names corrospoing to cropped photos\n","embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n","\n","for img, idx in loader:\n","    face, prob = mtcnn0(img, return_prob=True) \n","    if face is not None and prob>0.92:\n","        emb = resnet(face.unsqueeze(0))\n","        embedding_list.append(emb.detach()) \n","        name_list.append(idx_to_class[idx])        \n","\n","# save data\n","data = [embedding_list, name_list] \n","torch.save(data, 'resnet_data.pt') # saving data.pt file"],"metadata":{"id":"Jhy-6ikqkBuu","executionInfo":{"status":"ok","timestamp":1664796780121,"user_tz":-330,"elapsed":5554,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Using webcam recognize face\n","from google.colab.patches import cv2_imshow\n","\n","# loading data.pt file\n","load_data = torch.load('resnet_data.pt') \n","embedding_list = load_data[0] \n","name_list = load_data[1] \n","\n","# cam = cv2.VideoCapture(0) \n","video_stream()\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","\n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","    frame_coverted = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    img = PIL.Image.fromarray(frame_coverted)\n","\n","    img_cropped_list, prob_list = mtcnn(img, return_prob=True) \n","    \n","    if img_cropped_list is not None:\n","        boxes, _ = mtcnn.detect(img)\n","                \n","        for i, prob in enumerate(prob_list):\n","            if prob>0.90:\n","                emb = resnet(img_cropped_list[i].unsqueeze(0)).reshape(-1).detach() \n","                \n","                dist_list = [] # list of matched distances, minimum distance is used to identify the person\n","                \n","                for idx, emb_db in enumerate(embedding_list):\n","                    dist = torch.dist(emb, emb_db).item()\n","                    dist_list.append(dist)\n","\n","                min_dist = min(dist_list) # get minumum dist value\n","                min_dist_idx = dist_list.index(min_dist) # get minumum dist index\n","                name = name_list[min_dist_idx] # get name corrosponding to minimum dist\n","                \n","                box = boxes[i] \n","                \n","                original_frame = frame.copy() # storing copy of frame before drawing on it\n","                \n","                if min_dist<200.90:\n","                    frame = cv2.putText(frame, name+' '+str(min_dist), (int(box[0]),int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),1, cv2.LINE_AA)\n","                \n","                frame = cv2.rectangle(frame, (int(box[0]),int(box[1])) , (int(box[2]),int(box[3])), (255,0,0), 2)\n","\n","    cv2_imshow(frame)\n","        \n","    \n","    k = cv2.waitKey(1)\n","    if k%256==27: # ESC\n","        print('Esc pressed, closing...')\n","        break\n","        \n","    elif k%256==32: # space to save image\n","        print('Enter your name :')\n","        name = input()\n","        \n","        # create directory if not exists\n","        if not os.path.exists('photos/'+name):\n","            os.mkdir('photos/'+name)\n","            \n","        img_name = \"photos/{}/{}.jpg\".format(name, int(time.time()))\n","        cv2.imwrite(img_name, original_frame)\n","        print(\" saved: {}\".format(img_name))\n","        \n","        \n","# cam.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"xJU9BKagkGz3","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1iV6zuSFyWFGLk38GwhXeaE6Nm5O1xiBP"},"executionInfo":{"status":"ok","timestamp":1664796899218,"user_tz":-330,"elapsed":77952,"user":{"displayName":"Binod Binod","userId":"14980185732584765049"}},"outputId":"c3df03e1-395c-4709-c4c5-864f43625e86"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"ge3520SLlmWt"},"execution_count":null,"outputs":[]}]}